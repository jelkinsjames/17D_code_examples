{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jelkinsjames/17D_code_examples/blob/main/Lab_4_CJ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d8b80a5",
      "metadata": {
        "id": "0d8b80a5"
      },
      "source": [
        "##### Author: Jimin Kim (jk55@uw.edu)\n",
        "##### Version 1.5.0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c15dd830",
      "metadata": {
        "id": "c15dd830"
      },
      "source": [
        "# Lab 4 Report"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b76e12f",
      "metadata": {
        "id": "0b76e12f"
      },
      "source": [
        "## Group Members: Anita Chege, Julian James\n",
        "## Group Name for Leaderboard: Payday for CJ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d45e0cd",
      "metadata": {
        "id": "4d45e0cd"
      },
      "outputs": [],
      "source": [
        "#IMPORT CELL\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as st\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f63a0fa",
      "metadata": {
        "id": "4f63a0fa"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image as ipyimage #For displaying images in colab jupyter cell"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f900d0d0",
      "metadata": {
        "id": "f900d0d0"
      },
      "source": [
        "### Exercise 1: Construct Dictionaries from Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bba479e8",
      "metadata": {
        "id": "bba479e8",
        "outputId": "0a1877eb-a358-4adf-d7a8-4784cd757bc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "lab4_exercise1.PNG",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "image/png": {
              "width": 1000
            }
          },
          "execution_count": 3
        }
      ],
      "source": [
        "ipyimage('lab4_exercise1.PNG', width = 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f1a2e57",
      "metadata": {
        "id": "0f1a2e57"
      },
      "outputs": [],
      "source": [
        "# Converts CSV to a numpy dictionary.\n",
        "# @param file_path - the path to the CSV file.\n",
        "def convert_csv_to_dict(file_path):\n",
        "    \n",
        "    # YOUR CODE HERE\n",
        "    # Section 1.1 and 2.3 of Lab4_Lecture_Examples.ipynb might be helpful\n",
        "    csv = pd.read_csv(file_path) # reads in csv file as pandas dataframe\n",
        "    dict_object = {} #creates empty dictionary\n",
        "    for name in csv.columns: #for each name in the DataFrame columns, convert the value in that column to an entry in the dicitonary\n",
        "        dict_object[name] = csv[name].to_numpy()\n",
        "    return dict_object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b92b859",
      "metadata": {
        "id": "4b92b859",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "239a09fe-a0fb-40e7-a50e-bedf080f6717"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-24b6112b968c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mTSLA_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_csv_to_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TSLA.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-5b5e745004b4>\u001b[0m in \u001b[0;36mconvert_csv_to_dict\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Section 1.1 and 2.3 of Lab4_Lecture_Examples.ipynb might be helpful\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mcsv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdict_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'TSLA.csv'"
          ]
        }
      ],
      "source": [
        "TSLA_dict = convert_csv_to_dict('TSLA.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf7b05fa",
      "metadata": {
        "id": "bf7b05fa"
      },
      "outputs": [],
      "source": [
        "# Navigate to keys corresponding to 2nd and 4th columns (Open and Low prices) of TSLA.csv, \n",
        "# Print first 10 elements of each key.\n",
        "\n",
        "TSLA_column2 = \"Open\"\n",
        "TSLA_column4 = \"Low\"\n",
        "print(TSLA_dict[TSLA_column2][:10])\n",
        "print(TSLA_dict[TSLA_column4][:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e943cb82",
      "metadata": {
        "id": "e943cb82"
      },
      "outputs": [],
      "source": [
        "diabetes_dict = convert_csv_to_dict('diabetes.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ad77d50",
      "metadata": {
        "id": "3ad77d50"
      },
      "outputs": [],
      "source": [
        "# Navigate to keys corresponding to 2nd and 4th columns (Glucose and SkinThickness) of diabetes.csv, \n",
        "# Print first 10 elements of each key.\n",
        "\n",
        "diabetes_column2 = \"Glucose\"\n",
        "diabetes_column4 = \"SkinThickness\"\n",
        "print(diabetes_dict[diabetes_column2][:10])\n",
        "print(diabetes_dict[diabetes_column4][:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5eb0da37",
      "metadata": {
        "id": "5eb0da37"
      },
      "source": [
        "### Exercise 2: Bar graph with confidence intervals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aca3f480",
      "metadata": {
        "id": "aca3f480"
      },
      "outputs": [],
      "source": [
        "ipyimage('lab4_exercise2.PNG', width = 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfda82e0",
      "metadata": {
        "id": "dfda82e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "48dea61c-d405-4c0b-fbfd-e061a3f20caa"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-299c2e6cad9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Split the data into diabetic and non-diabetic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdiabetes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'diabetes.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdiabetes_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiabetes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'diabetes.csv'"
          ]
        }
      ],
      "source": [
        "# Load diabetes.csv \n",
        "# Split the data into diabetic and non-diabetic\n",
        "\n",
        "diabetes = pd.read_csv('diabetes.csv')\n",
        "\n",
        "diabetes_np = diabetes.to_numpy()\n",
        "diabetes_pos_ind = diabetes_np[:, -1] == 1 #Gets the last column and checks if entry is diabetic or not.\n",
        "diabetes_neg_ind = diabetes_np[:, -1] == 0\n",
        "\n",
        "diabetes_pos = diabetes_np[diabetes_pos_ind, :] #Using boolean masking, gets the rest of the data of the entry.\n",
        "diabetes_neg = diabetes_np[diabetes_neg_ind, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38c0873e",
      "metadata": {
        "id": "38c0873e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "3cc08be7-2959-430d-dc57-3de5d6a97ae4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-a23d09e33102>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# non-diabetic metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnon_diabetic_glucose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiabetes_neg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mnon_diabetic_bp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiabetes_neg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mnon_diabetic_bmi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiabetes_neg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'diabetes_neg' is not defined"
          ]
        }
      ],
      "source": [
        "# Extract glucose, blood pressure, and BMI metrics from diabetic and non-diabetic\n",
        "\n",
        "# non-diabetic metrics\n",
        "non_diabetic_glucose = diabetes_neg[:,1]\n",
        "non_diabetic_bp = diabetes_neg[:,2]\n",
        "non_diabetic_bmi = diabetes_neg[:,5]\n",
        "\n",
        "# diabetic metrics\n",
        "diabetic_glucose = diabetes_pos[:,1]\n",
        "diabetic_bp = diabetes_pos[:,2]\n",
        "diabetic_bmi = diabetes_pos[:,3]\n",
        "\n",
        "non_diabetic_list = [non_diabetic_glucose, non_diabetic_bp, non_diabetic_bmi]\n",
        "diabetic_list = [diabetic_glucose, diabetic_bp, diabetic_bmi]\n",
        "\n",
        "non_diabetic_bar_labels = ['non_diabetic_glucose', 'non_diabetic_bp', 'non_diabetic_bmi']\n",
        "diabetic_bar_labels = ['diabetic_glucose', 'diabetic_bp', 'diabetic_bmi']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14e87c48",
      "metadata": {
        "id": "14e87c48"
      },
      "outputs": [],
      "source": [
        "def produce_bargraph_CI(data_vec_list, conf_level, bar_labels):\n",
        "    \n",
        "    # YOUR CODE HERE \n",
        "    # THE FUNCTION SHOULD OUTPUT THE PLOT\n",
        "    # MAKE SURE YOUR LABELS (bar labels, plot titles are large enough)\n",
        "    data = np.array(data_vec_list) #Turns the vector list into a numpy array.\n",
        "    h_list = [] #Creating empty lists for the h and mean.\n",
        "    mean_list = [] \n",
        "    for i in range(len(data)): \n",
        "        data_column = data[i] #Gets data for calculation.\n",
        "        CI_lower, CI_upper = st.t.interval(alpha=conf_level, df=len(data_column)-1, loc=np.mean(data_column), \\\n",
        "                                          scale=st.sem(data_column)) # Calculates our confidence interval.\n",
        "        h_list.append(CI_upper - np.mean(data_column)) \n",
        "        mean_list.append(np.mean(data_column)) \n",
        "    print(h_list)\n",
        "    \n",
        "    fig = plt.figure(figsize=(20, 10))\n",
        "    plt.bar(bar_labels, mean_list, color = 'blue', yerr=h_list, ecolor ='grey', error_kw=dict(lw=5, capsize=50, capthick=5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cccb2595",
      "metadata": {
        "id": "cccb2595"
      },
      "outputs": [],
      "source": [
        "produce_bargraph_CI(data_vec_list = non_diabetic_list, conf_level = 0.99, bar_labels = non_diabetic_bar_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4452891f",
      "metadata": {
        "id": "4452891f"
      },
      "outputs": [],
      "source": [
        "produce_bargraph_CI(data_vec_list = diabetic_list, conf_level = 0.95, bar_labels = diabetic_bar_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58bb0604",
      "metadata": {
        "id": "58bb0604"
      },
      "source": [
        "### Exercise 3: Rolling Mean/Median Function from Scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fbe4b51",
      "metadata": {
        "id": "1fbe4b51"
      },
      "outputs": [],
      "source": [
        "ipyimage('lab4_exercise3.PNG', width = 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21b82271",
      "metadata": {
        "id": "21b82271"
      },
      "outputs": [],
      "source": [
        "# Load stock datasets\n",
        "\n",
        "tesla = pd.read_csv('TSLA.csv') \n",
        "tesla_np = tesla.to_numpy()\n",
        "\n",
        "google = pd.read_csv('GOOGL.csv') \n",
        "google_np = google.to_numpy()\n",
        "\n",
        "dji = pd.read_csv('DJI.csv') \n",
        "dji_np = dji.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c6146a0",
      "metadata": {
        "id": "9c6146a0"
      },
      "outputs": [],
      "source": [
        "# Extract closing price for each stock data\n",
        "\n",
        "tesla_np_closing = tesla_np[:, 4]\n",
        "google_np_closing = google_np[:, 4]\n",
        "DJI_np_closing = dji_np[:, 4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da865892",
      "metadata": {
        "id": "da865892"
      },
      "outputs": [],
      "source": [
        "def smooth_data(data_arr, smooth_type, window_size):\n",
        "\n",
        "    df = pd.DataFrame(data_arr)\n",
        "    print(smooth_type)\n",
        "    if (smooth_type == 'mean'):\n",
        "        smoothed_data_arr = df.rolling(window_size).mean()\n",
        "    if (smooth_type == 'median'):\n",
        "        smoothed_data_arr = df.rolling(window_size).median()\n",
        "\n",
        "    return smoothed_data_arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae1e8a2b",
      "metadata": {
        "id": "ae1e8a2b"
      },
      "outputs": [],
      "source": [
        "# Tesla closing prices, smooth_type = 'mean', window_size = 100\n",
        "# Note your smoothed data will be shorter than the original\n",
        "\n",
        "smoothed_tsla_closing  = smooth_data(tesla_np_closing, smooth_type = 'mean', window_size = 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61a6ba44",
      "metadata": {
        "id": "61a6ba44"
      },
      "outputs": [],
      "source": [
        "# plot smoothed_tsla_closing on top of tesla_np_closing\n",
        "\n",
        "fig = plt.figure(figsize=(23,5))\n",
        "\n",
        "# Repeating plt.plot() functions automatically overlay one plot to the other\n",
        "plt.plot(smoothed_tsla_closing, linewidth = 5, color = 'red') \n",
        "plt.plot(tesla_np_closing, linewidth = 5, color = 'black')\n",
        "plt.xticks(fontsize=20) # adjusts the size of x-axis ticks\n",
        "plt.yticks(fontsize=20) # adjusts the size of y-axis ticks\n",
        "plt.ylabel('Closing Price', fontsize = 25)\n",
        "plt.xlabel('Days', fontsize = 25)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29535d23",
      "metadata": {
        "id": "29535d23"
      },
      "outputs": [],
      "source": [
        "# Google closing prices, smooth_type = 'median', window_size = 150\n",
        "# Note your smoothed data will be shorter than the original\n",
        "\n",
        "smoothed_google_closing  = smooth_data(google_np_closing, smooth_type = 'median', window_size = 150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0d4ced3",
      "metadata": {
        "id": "f0d4ced3"
      },
      "outputs": [],
      "source": [
        "# plot smoothed_google_closing on top of google_np_closing\n",
        "\n",
        "fig = plt.figure(figsize=(23,5))\n",
        "\n",
        "# Repeating plt.plot() functions automatically overlay one plot to the other\n",
        "plt.plot(smoothed_google_closing, linewidth = 5, color = 'red') \n",
        "plt.plot(google_np_closing, linewidth = 5, color = 'black')\n",
        "plt.xticks(fontsize=20) # adjusts the size of x-axis ticks\n",
        "plt.yticks(fontsize=20) # adjusts the size of y-axis ticks\n",
        "plt.ylabel('Closing Price', fontsize = 25)\n",
        "plt.xlabel('Days', fontsize = 25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec2b672b",
      "metadata": {
        "id": "ec2b672b"
      },
      "outputs": [],
      "source": [
        "# Dow Jones Index closing prices, smooth_type = 'mean', window_size = 200\n",
        "# Note your smoothed data will be shorter than the original\n",
        "\n",
        "smoothed_dji_closing  = smooth_data(DJI_np_closing, smooth_type = 'mean', window_size = 200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "beb96963",
      "metadata": {
        "id": "beb96963"
      },
      "outputs": [],
      "source": [
        "# plot smoothed_dji_closing on top of dji_np_closing\n",
        "\n",
        "fig = plt.figure(figsize=(23,5))\n",
        "\n",
        "# Repeating plt.plot() functions automatically overlay one plot to the other\n",
        "plt.plot(smoothed_dji_closing, linewidth = 5, color = 'red') \n",
        "plt.plot(DJI_np_closing, linewidth = 5, color = 'black')\n",
        "plt.xticks(fontsize=20) # adjusts the size of x-axis ticks\n",
        "plt.yticks(fontsize=20) # adjusts the size of y-axis ticks\n",
        "plt.ylabel('Closing Price', fontsize = 25)\n",
        "plt.xlabel('Days', fontsize = 25)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00c5e941",
      "metadata": {
        "id": "00c5e941"
      },
      "source": [
        "## Extra credit: Code efficiency\n",
        "### Achieve a runtime speed of < 50ms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a2e58cd",
      "metadata": {
        "id": "9a2e58cd"
      },
      "outputs": [],
      "source": [
        "timeit -n 1 -r 7 smoothed_google_closing  = smooth_data(google_np_closing, smooth_type = 'median', window_size = 150)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e1317ff",
      "metadata": {
        "id": "0e1317ff"
      },
      "source": [
        "### Exercise 4: Ranking Daily Stock Surges/Crashes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8270903f",
      "metadata": {
        "id": "8270903f"
      },
      "outputs": [],
      "source": [
        "ipyimage('lab4_exercise4.PNG', width = 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e42ebb9",
      "metadata": {
        "id": "1e42ebb9"
      },
      "outputs": [],
      "source": [
        "def detect_surge_crash(filepath, detect_type, num_output_dates):\n",
        "    \n",
        "    csv = pd.read_csv(filepath)\n",
        "    dict_object1 = {}\n",
        "    csv_np = csv.to_numpy()\n",
        "    \n",
        "    arr_date = csv_np[:, 0]\n",
        "    price_change_arr = np.subtract(csv_np[:, 4], csv_np[:, 1])\n",
        "    \n",
        "    #creates dictionary with price changes as keys and their corresponding dates\n",
        "    #as the values\n",
        "    for i in range(len(price_change_arr)):\n",
        "        dict_object1[price_change_arr[i]] = arr_date[i]\n",
        "    \n",
        "    #initializes empty list outputs\n",
        "    date_list = []\n",
        "    price_change_list = []\n",
        "    \n",
        "    #get min or max in price_change_arr, add it to price_list and \n",
        "    #its corresponding date to date_list\n",
        "\n",
        "    for i in range(num_output_dates): #number of prices/dates to output in list\n",
        "        \n",
        "        if (detect_type == 'surge'):    \n",
        "            x = max(price_change_arr)   #determine max value in price array\n",
        "            price_change_list.append(x) #add max value to output list\n",
        "            date_list.append(dict_object1.get(x)) #add relevant date to output list\n",
        "            del dict_object1[x]; #delete the max value to get the next largest mav val\n",
        "\n",
        "            \n",
        "        if (detect_type == 'crash'):    \n",
        "            x = min(price_change_arr)\n",
        "            price_change_list.append(x)\n",
        "            date_list.append(dict_object1.get(x))\n",
        "            del dict_object1[x];\n",
        "\n",
        "    return date_list, price_change_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84d8ff18",
      "metadata": {
        "id": "84d8ff18"
      },
      "outputs": [],
      "source": [
        "date_list_t, price_change_list_t = detect_surge_crash(filepath = 'TSLA.csv', detect_type = 'surge', num_output_dates = 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3b40e43",
      "metadata": {
        "id": "b3b40e43"
      },
      "outputs": [],
      "source": [
        "print(date_list_t, price_change_list_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a3b62f7",
      "metadata": {
        "id": "6a3b62f7"
      },
      "outputs": [],
      "source": [
        "date_list_g, price_change_list_g = detect_surge_crash(filepath = 'GOOGL.csv', detect_type = 'crash', num_output_dates = 7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ae6a233",
      "metadata": {
        "id": "5ae6a233"
      },
      "outputs": [],
      "source": [
        "print(date_list_g, price_change_list_g)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9dc480d9",
      "metadata": {
        "id": "9dc480d9"
      },
      "source": [
        "## Extra credit: Code efficiency\n",
        "### Achieve a runtime speed of < 10ms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94179472",
      "metadata": {
        "id": "94179472"
      },
      "outputs": [],
      "source": [
        "timeit -n 1 -r 7 date_list_t, price_change_list_t = detect_surge_crash(filepath = \"TSLA.csv\", detect_type = 'surge', num_output_dates = 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5605702f",
      "metadata": {
        "id": "5605702f"
      },
      "source": [
        "### Exercise 5: Human Debugger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a5bff99",
      "metadata": {
        "id": "4a5bff99"
      },
      "outputs": [],
      "source": [
        "ipyimage('lab4_exercise5.PNG', width = 1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61790f59",
      "metadata": {
        "id": "61790f59"
      },
      "source": [
        "### Faulty function #1 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d54fe90",
      "metadata": {
        "id": "7d54fe90"
      },
      "outputs": [],
      "source": [
        "def average_data_per_col(arr_2d):\n",
        "    \n",
        "    # NOTE FROM YOUR FRIEND PREPARING FOR STARBUCKS SOFTWARE ENGINEER TECH INTERVIEW \n",
        "    \"\"\"  The function takes numpy 2d array as an input, computes mean for each column data, and outputs 1D array \n",
        "         with the length equal to the # of columns.\n",
        "         \n",
        "         For some reason I keep getting errors.... I need your help to debug the code.\n",
        "         I need this position so I can get free ice lattes... :(\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    # placeholder for averaged values\n",
        "    averaged_data = ()\n",
        "    \n",
        "    # Loop through each column data to compute mean and append to averaged_data \n",
        "    for k in range(len(arr_2d[:, 0])):\n",
        "        \n",
        "        averaged_column_data = np.mean(arr_2d[:, k])\n",
        "        averaged_data.append(averaged_column_data)\n",
        "        \n",
        "    # Return numpy array form of the averaged_data\n",
        "    return np.array(averaged_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f4ddb85",
      "metadata": {
        "id": "8f4ddb85"
      },
      "outputs": [],
      "source": [
        "# Load diabetes.csv and convert to numpy array\n",
        "\n",
        "diabetes = pd.read_csv('diabetes.csv')\n",
        "diabetes_np = diabetes.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb0769db",
      "metadata": {
        "id": "bb0769db"
      },
      "outputs": [],
      "source": [
        "# Run faulty function 1\n",
        "\n",
        "averaged_diabetic_attributes =  average_data_per_col(diabetes_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "662c696e",
      "metadata": {
        "id": "662c696e"
      },
      "outputs": [],
      "source": [
        "# YOUR FIXED FUNCTION HERE\n",
        "# Make sure you comment on your fixes\n",
        "\n",
        "def average_data_per_col_fixed(arr_2d):\n",
        "    \n",
        "    # YOUR CODE HERE\n",
        "    averaged_data = []\n",
        "    columns = len(arr_2d[0])\n",
        "    for k in range(columns):\n",
        "        averaged_column_data = np.mean(arr_2d[:, k])\n",
        "        averaged_data.append(averaged_column_data)\n",
        "    np.array(averaged_data)\n",
        "    return averaged_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb1aad89",
      "metadata": {
        "id": "cb1aad89"
      },
      "outputs": [],
      "source": [
        "# Test your fixed function\n",
        "\n",
        "averaged_diabetic_attributes =  average_data_per_col_fixed(diabetes_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97927a5b",
      "metadata": {
        "id": "97927a5b"
      },
      "outputs": [],
      "source": [
        "# Compare with correct results\n",
        "\n",
        "correct_result_func1 = np.load('E5_correct_output_1.npy')\n",
        "\n",
        "# Should return True if the result is correct\n",
        "np.sum(np.round(correct_result_func1, 3) == np.round(averaged_diabetic_attributes, 3)) == len(correct_result_func1) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "283bc04d",
      "metadata": {
        "id": "283bc04d"
      },
      "source": [
        "### Faulty function #2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7297d884",
      "metadata": {
        "id": "7297d884"
      },
      "outputs": [],
      "source": [
        "def daily_stock_change_2_normalized_percentage(opening_price_arr, closing_price_arr):\n",
        "    \n",
        "    # NOTE FROM YOUR FRIEND WHO INVESTED IN TESLA\n",
        "    \"\"\"  I want to write a function which takes 2 1D numpy arrays of each corresponding to opening/closing prices of stock\n",
        "         and output 1D array of daily stock change in percentages. \n",
        "         \n",
        "         I want the percentages scale to be in a scale such that 1 = 100%, -0.5 = -50%, 1.5 = 150%  etc.\n",
        "         For example, day 1 opening: $10, day 1 closing: $15, change in scaled percecntage: 0.5.\n",
        "         \n",
        "         I am not really getting errors but the numbers don't look right... Can you help me?? :'( \n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    # placeholder for change percentage values\n",
        "    change_percentages = np.zeros(len(opening_price_arr), dtype = 'int')\n",
        "    \n",
        "    # Loop through each opening/closing price to compute the change percentage\n",
        "    for date_num in range(len(opening_price_arr)):\n",
        "        \n",
        "        change_percentages[date_num] = opening_price_arr[date_num] - closing_price_arr[date_num] / opening_price_arr[date_num]\n",
        "    \n",
        "    return change_percentages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a6008e0",
      "metadata": {
        "id": "8a6008e0"
      },
      "outputs": [],
      "source": [
        "# Load tsla.csv and convert to numpy array\n",
        "\n",
        "tesla = pd.read_csv('TSLA.csv') \n",
        "tesla_np = tesla.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3486e41e",
      "metadata": {
        "id": "3486e41e"
      },
      "outputs": [],
      "source": [
        "# Run faulty function 2\n",
        "\n",
        "change_percentages = daily_stock_change_2_normalized_percentage(tesla_np[:, 1], tesla_np[:, 4])\n",
        "print(change_percentages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0a52a2e",
      "metadata": {
        "id": "b0a52a2e"
      },
      "outputs": [],
      "source": [
        "# YOUR FIXED FUNCTION HERE\n",
        "# Make sure you comment on your fixes\n",
        "\n",
        "def daily_stock_change_2_normalized_percentage_fixed(opening_price_arr, closing_price_arr):\n",
        "    \n",
        "    # placeholder for change percentage values\n",
        "    change_percentages = np.zeros(len(opening_price_arr), dtype = 'float') #changed type to float\n",
        "    \n",
        "    # Loop through each opening/closing price to compute the change percentage\n",
        "    for date_num in range(len(opening_price_arr)):\n",
        "        # Below: switched around the closing price and opening price arrays, and put them in parenthesis so the operation happens\n",
        "        # first.\n",
        "        change_percentages[date_num] = (closing_price_arr[date_num] - opening_price_arr[date_num]) / opening_price_arr[date_num]\n",
        "        \n",
        "    return change_percentages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0a62383",
      "metadata": {
        "id": "b0a62383"
      },
      "outputs": [],
      "source": [
        "# Test your fixed function\n",
        "\n",
        "change_percentages = daily_stock_change_2_normalized_percentage_fixed(tesla_np[:, 1], tesla_np[:, 4])\n",
        "print(change_percentages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3abcd16f",
      "metadata": {
        "id": "3abcd16f"
      },
      "outputs": [],
      "source": [
        "# Compare with correct results\n",
        "\n",
        "correct_result_func2 = np.load('E5_correct_output_2.npy')\n",
        "\n",
        "# Should return True if the result is correct\n",
        "np.sum(np.round(correct_result_func2, 3) == np.round(change_percentages, 3)) == len(correct_result_func2) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9f376cc",
      "metadata": {
        "id": "f9f376cc"
      },
      "source": [
        "### Faulty function #3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "54f49798",
      "metadata": {
        "id": "54f49798"
      },
      "outputs": [],
      "source": [
        "# YOUR FIXED FUNCTION HERE\n",
        "# Make sure you comment on your fixes\n",
        "\n",
        "def subset_diabetes_by_age_fixed(diabetes_data):\n",
        "    \n",
        "    # Extract the age column of the diabetes_data \n",
        "    age_column = diabetes_data['Age'] #changed attempt at acessing an array to acessing the DataFrame column for Age.\n",
        "    \n",
        "    # Construct boolean mask for each age group \n",
        "    age_20_40_bool_mask = (age_column > 20) + (age_column < 40) #Put parentheses on comparators.\n",
        "    age_40_60_bool_mask = (age_column > 40) + (age_column < 60)\n",
        "    age_60_80_bool_mask = (age_column > 60) + (age_column < 80)\n",
        "    \n",
        "    # Get glucose data for each age group via applying the boolean mask for each age group\n",
        "    glucose_col = diabetes_data['Glucose'] # gets glucose column\n",
        "    age_20_40_glucose = glucose_col[age_20_40_bool_mask] #applies mask to the column without trying to access it like an array,\n",
        "    age_40_60_glucose = glucose_col[age_40_60_bool_mask]\n",
        "    age_60_80_glucose = glucose_col[age_60_80_bool_mask]\n",
        "    \n",
        "    # Plot the histogram for each age group in 3 x 1 subplot\n",
        "    fig = plt.figure(figsize=(15,7))\n",
        "    \n",
        "    plt.subplot(3,1,1)\n",
        "    \n",
        "    plt.hist(age_20_40_glucose, bins = 50)\n",
        "    plt.title('Age 20 to 40', fontsize = 15)\n",
        "    \n",
        "    plt.subplot(3,1,2)\n",
        "    \n",
        "    plt.hist(age_40_60_glucose, bins = 50)\n",
        "    plt.title('Age 40 to 60', fontsize = 15)\n",
        "    \n",
        "    plt.subplot(3,1,3)\n",
        "    \n",
        "    plt.hist(age_60_80_glucose, bins = 50)\n",
        "    plt.title('Age 60 to 80', fontsize = 15)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6356d6db",
      "metadata": {
        "id": "6356d6db"
      },
      "outputs": [],
      "source": [
        "# Load diabetes.csv as pandas dataframe\n",
        "\n",
        "diabetes = pd.read_csv('diabetes.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf9e640a",
      "metadata": {
        "id": "bf9e640a"
      },
      "outputs": [],
      "source": [
        "# Run faulty function 3\n",
        "\n",
        "subset_diabetes_by_age(diabetes_data = diabetes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31505293",
      "metadata": {
        "id": "31505293"
      },
      "outputs": [],
      "source": [
        "# YOUR FIXED FUNCTION HERE\n",
        "# Make sure you comment on your fixes\n",
        "\n",
        "def subset_diabetes_by_age_fixed(diabetes_data):\n",
        "    \n",
        "    # Extract the age column of the diabetes_data \n",
        "    age_column = diabetes_data['Age'] \n",
        "    \n",
        "    # Construct boolean mask for each age group \n",
        "    age_20_40_bool_mask = (age_column > 20) + (age_column < 40)\n",
        "    age_40_60_bool_mask = (age_column > 40) + (age_column < 60)\n",
        "    age_60_80_bool_mask = (age_column > 60) + (age_column < 80)\n",
        "    \n",
        "    # Get glucose data for each age group via applying the boolean mask for each age group\n",
        "    glucose_col = diabetes_data['Glucose']\n",
        "    age_20_40_glucose = glucose_col[age_20_40_bool_mask]\n",
        "    age_40_60_glucose = glucose_col[age_40_60_bool_mask]\n",
        "    age_60_80_glucose = glucose_col[age_60_80_bool_mask]\n",
        "    \n",
        "    # Plot the histogram for each age group in 3 x 1 subplot\n",
        "    fig = plt.figure(figsize=(15,7))\n",
        "    \n",
        "    plt.subplot(3,1,1)\n",
        "    \n",
        "    plt.hist(age_20_40_glucose, bins = 50)\n",
        "    plt.title('Age 20 to 40', fontsize = 15)\n",
        "    \n",
        "    plt.subplot(3,1,2)\n",
        "    \n",
        "    plt.hist(age_40_60_glucose, bins = 50)\n",
        "    plt.title('Age 40 to 60', fontsize = 15)\n",
        "    \n",
        "    plt.subplot(3,1,3)\n",
        "    \n",
        "    plt.hist(age_60_80_glucose, bins = 50)\n",
        "    plt.title('Age 60 to 80', fontsize = 15)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b0e259f",
      "metadata": {
        "id": "8b0e259f"
      },
      "outputs": [],
      "source": [
        "# Test your fixed function\n",
        "# Compare your plot with the correct plot provided in template folder\n",
        "\n",
        "subset_diabetes_by_age_fixed(diabetes_data = diabetes)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "f900d0d0"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}